{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step into our cozy coding haven, where each line of code wraps us in a comforting embrace.\n",
    "\n",
    "# Ah, the 'import pandas as pd' line ushers in the mighty pandas library, like opening the door to a trusted friend.\n",
    "# It's as if we're welcoming an esteemed guest into our cozy home, ready to embark on a data-driven adventure.\n",
    "\n",
    "# This line of code imports the pandas library and aliases it as pd.\n",
    "# It's like inviting a trusted friend into our coding sanctuary, someone who's got our back when it comes to handling data.\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, with the 'df = pd.read_csv('../MonthlySales.csv')' line, we embark on a journey through the data realms.\n",
    "# It's like opening a treasure chest filled with precious information, ready to be explored and analyzed.\n",
    "\n",
    "# This line of code reads a CSV file named 'MonthlySales.csv' and stores its contents in a DataFrame called df.\n",
    "# It's like discovering a treasure chest full of valuable data, waiting to be uncovered and analyzed.\n",
    "df = pd.read_csv('../MonthlySales.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ah, the 'df' variable holds the key to our data treasure.\n",
    "# It's like a map guiding us through the vast expanse of our data landscape, ready to reveal its secrets.\n",
    "\n",
    "# This 'df' variable represents a DataFrame that contains our data treasure.\n",
    "# It's like possessing a map that guides us through the vast expanse of our data landscape, revealing its secrets and insights.\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yo, we 'bout to dive deep into the data game, so we bringin' in the JSON crew.\n",
    "# It's like hittin' up the data wizards to put some magic on our files, you dig?\n",
    "\n",
    "# This 'import json' line brings in the JSON crew, allowing us to work with JSON data.\n",
    "# It's like calling in the data wizards to work their magic on our files and unlock their secrets.\n",
    "\n",
    "import json\n",
    "\n",
    "# Check it, we're bringin' in the JSON normalization squad straight outta the pandas block.\n",
    "# It's like havin' the data SWAT team on speed dial, ready to handle any format like pros.\n",
    "\n",
    "# This 'from pandas import json_normalize' line imports the json_normalize function from the pandas library.\n",
    "# It's like having the data SWAT team on standby, ready to normalize our JSON data into a structured format.\n",
    "\n",
    "from pandas import json_normalize\n",
    "\n",
    "# A'ight, we crack open the JSON file and load it up.\n",
    "# It's like poppin' the lock on the front door to our data crib and lettin' the numbers flow in for a chill session.\n",
    "\n",
    "# This 'with open('../MonthlySalesByCategory.json') as json_data' line opens the JSON file for reading.\n",
    "# It's like unlocking the front door to our data crib and welcoming the numbers inside for a chill session.\n",
    "with open('../MonthlySalesByCategory.json') as json_data:\n",
    "    # This 'd = json.load(json_data)' line loads the JSON data from the file into a variable called 'd'.\n",
    "    # It's like inviting the numbers inside our data crib, ready to be analyzed and explored.\n",
    "    d = json.load(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A'ight, we 'bout to lay down some serious data moves, so we callin' up the JSON normalization squad.\n",
    "# It's like bringin' in the heavy hitters to unpack our data stash, you feel me?\n",
    "\n",
    "# This 'json_normalize' function call normalizes our JSON data into a structured DataFrame.\n",
    "# It's like bringing in the heavy hitters to unpack and organize our data stash, making it ready for analysis.\n",
    "# The parameters specify the structure of the JSON data, with 'monthlySales' being the nested key to normalize,\n",
    "# and ['category', 'region'] indicating additional keys to include as columns in the DataFrame.\n",
    "df = json_normalize(d['contents'], 'monthlySales', ['category', 'region'])\n",
    "\n",
    "# Check it, now we got our data all nice and normalized, ready to rock and roll.\n",
    "# It's like havin' a fresh set of blueprints for our data mansion, laid out and ready to build.\n",
    "\n",
    "# This line displays the DataFrame 'df', showing the normalized data.\n",
    "# It's like admiring the fresh set of blueprints for our data mansion, envisioning the insights and discoveries that lie ahead.\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A'ight, we 'bout to bring some data flavor into our crib, so we callin' up the parquet pandas.\n",
    "# It's like invitin' a squad of data architects to design the blueprint for our data mansion.\n",
    "\n",
    "# This 'import pyarrow.parquet as pq' line brings in the parquet pandas library under the alias 'pq'.\n",
    "# It's like inviting a squad of data architects to our data mansion, ready to design the blueprint in Parquet format.\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yo, we bringin' in the data masterpiece straight into our crib.\n",
    "# It's like havin' the blueprint for our data mansion delivered right to our doorstep.\n",
    "\n",
    "# This 'pq.read_table' function call reads a Parquet file and returns a Table object.\n",
    "# It's like having the blueprint for our data mansion delivered right to our doorstep,\n",
    "# ready for us to explore and analyze.\n",
    "table = pq.read_table('../MonthlyProductSales.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yo, we ain't just stoppin' at the blueprint, we turnin' it into a livable space right in our crib.\n",
    "# It's like takin' them data blueprints and buildin' our data mansion from the ground up.\n",
    "\n",
    "# This 'table.to_pandas()' function call converts the Parquet Table object into a pandas DataFrame.\n",
    "# It's like turning the data blueprints into a livable space in our data mansion,\n",
    "# allowing us to explore and analyze the data more comfortably.\n",
    "table.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yo, listen up! If you ain't got html5lib installed, you better go get it.\n",
    "# Just hit up the pip and drop that install command like it's hot, you know what I'm sayin'?\n",
    "\n",
    "# Check it, we 'bout to raid the data vault straight from a HTML site.\n",
    "# It's like sneakin' into the backdoor of our data mansion and grabbin' all them state abbreviations.\n",
    "\n",
    "# This line of code reads HTML content from the specified URL and parses it to extract tabular data.\n",
    "# pd.read_html() is a pandas function specifically designed to scrape HTML tables and return them as a list of DataFrames.\n",
    "# The URL provided leads to a Wikipedia page listing U.S. state abbreviations, so we're scraping that data.\n",
    "# If you don't have the html5lib library installed, you might encounter issues with parsing the HTML content.\n",
    "df = pd.read_html('https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yo, check it! We're grabbin' the juicy part of our data stash, straight outta the HTML grab.\n",
    "# It's like sifting through the treasure chest in our data mansion and snaggin' the golden nuggets.\n",
    "\n",
    "# This line of code selects the first element (index 0) from the list of DataFrames obtained from reading the HTML page.\n",
    "# When we read HTML using pd.read_html(), it returns a list of DataFrames, each representing a table found on the page.\n",
    "# We're specifically interested in the first table, which contains the states and their abbreviations.\n",
    "df_usa = df[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alright, let's get down to business and clean up our data crib.\n",
    "\n",
    "# This line of code drops the first 11 rows from our DataFrame df_usa.\n",
    "# It's like sweeping away the clutter at the entrance of our data mansion, getting rid of any unnecessary information.\n",
    "# These rows typically contain header information or introductory text that we don't need for our analysis.\n",
    "df_usa_cleaned = df_usa.drop(df_usa.index[range(0, 11)])\n",
    "\n",
    "# Now, we drop columns 10 to 14 (inclusive) from our DataFrame df_usa_cleaned.\n",
    "# It's like renovating our data mansion's kitchen, getting rid of outdated appliances and unnecessary clutter.\n",
    "# These columns likely contain additional information that we don't need for our analysis, so we're removing them.\n",
    "final_df = df_usa_cleaned.drop(df_usa_cleaned.columns[10:15], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to give our columns some proper names and organize our data mansion.\n",
    "\n",
    "# This line of code renames the columns in our DataFrame final_df.\n",
    "# It's like labeling the rooms in our data mansion, making it easier to navigate and understand.\n",
    "# Each column is assigned a new name based on its position in the DataFrame.\n",
    "final_df.rename(columns={\n",
    "    0: 'Region Name',\n",
    "    1: 'Region Status',\n",
    "    2: 'ISO',\n",
    "    3: 'ANSI_Letter',\n",
    "    4: 'ANSI_Code',\n",
    "    5: 'USPS',\n",
    "    6: 'USCG',\n",
    "    7: 'GPO',\n",
    "    8: 'AP',\n",
    "    9: 'Other Abbreviations'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to reset the index of our rows and get things back in order.\n",
    "\n",
    "# This line of code resets the index of the rows in our DataFrame final_df.\n",
    "# It's like reorganizing the rooms in our data mansion, ensuring everything is in its proper place.\n",
    "# By setting drop=True, we're dropping the current index and replacing it with a new sequential index.\n",
    "final_df_reset = final_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
